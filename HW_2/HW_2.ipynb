{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install g2p-en\n",
    "!pip install praatio"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2PWoD_nr-teM",
    "outputId": "e1c7fe72-6bb9-4ffc-fc52-b19622d6a290"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting g2p-en\n",
      "  Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.1/3.1 MB\u001B[0m \u001B[31m22.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from g2p-en) (1.22.4)\n",
      "Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.10/dist-packages (from g2p-en) (3.8.1)\n",
      "Requirement already satisfied: inflect>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from g2p-en) (6.0.4)\n",
      "Collecting distance>=0.1.3 (from g2p-en)\n",
      "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m180.3/180.3 kB\u001B[0m \u001B[31m13.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect>=0.3.1->g2p-en) (1.10.7)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.4->g2p-en) (8.1.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.4->g2p-en) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.4->g2p-en) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.4->g2p-en) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect>=0.3.1->g2p-en) (4.5.0)\n",
      "Building wheels for collected packages: distance\n",
      "  Building wheel for distance (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16258 sha256=1ffccef406f4ffb510031ae2ddcb0d7f31b335a9dd8c3fd095cffc9c00f91238\n",
      "  Stored in directory: /root/.cache/pip/wheels/e8/bb/de/f71bf63559ea9a921059a5405806f7ff6ed612a9231c4a9309\n",
      "Successfully built distance\n",
      "Installing collected packages: distance, g2p-en\n",
      "Successfully installed distance-0.1.3 g2p-en-2.1.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting praatio\n",
      "  Downloading praatio-6.0.0-py3-none-any.whl (79 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m79.2/79.2 kB\u001B[0m \u001B[31m3.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from praatio) (4.5.0)\n",
      "Installing collected packages: praatio\n",
      "Successfully installed praatio-6.0.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from g2p_en import G2p\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from praatio import textgrid as tgio\n",
    "from praatio.data_classes.interval_tier import Interval"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BWVVPTyb-glw",
    "outputId": "016190cf-72ca-4d57-b84f-b53d9d7e17d6"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/cmudict.zip.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def make_frames(wav):\n",
    "    return torchaudio.compliance.kaldi.mfcc(wav)\n",
    "\n",
    "class LibriSpeech(torch.utils.data.Dataset):\n",
    "    def __init__(self, url='dev-clean'):\n",
    "        super().__init__()\n",
    "        self.librispeech = torchaudio.datasets.LIBRISPEECH('.', url=url, download=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.librispeech)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        wav, sr, text, speaker_id, chapter_id, utterance_id = self.librispeech[index]\n",
    "        return make_frames(wav), sr, text, speaker_id, chapter_id, utterance_id\n",
    "  \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim=13, subsample_dim=128, hidden_dim=1024):\n",
    "        super().__init__()\n",
    "        self.subsample = nn.Conv1d(input_dim, subsample_dim, 5, stride=4, padding=3)\n",
    "        self.lstm = nn.LSTM(subsample_dim, hidden_dim, batch_first=True, num_layers=3, dropout=0.2)\n",
    "\n",
    "    def subsampled_lengths(self, input_lengths):\n",
    "        # https://github.com/vdumoulin/conv_arithmetic\n",
    "        p, k, s = self.subsample.padding[0], self.subsample.kernel_size[0], self.subsample.stride[0]\n",
    "        o = input_lengths + 2 * p - k\n",
    "        o = torch.floor(o / s + 1)\n",
    "        return o.int()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        x = self.subsample(x.mT).mT\n",
    "        x = x.relu()\n",
    "        x, _ = self.lstm(x)\n",
    "        return x.relu()\n",
    "\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.g2p = G2p()\n",
    "\n",
    "        # http://www.speech.cs.cmu.edu/cgi-bin/cmudict\n",
    "        self.rdictionary = [\"ε\", # CTC blank\n",
    "                            \" \",\n",
    "                            \"AA0\", \"AA1\", \"AE0\", \"AE1\", \"AH0\", \"AH1\", \"AO0\", \"AO1\", \"AW0\", \"AW1\", \"AY0\", \"AY1\",\n",
    "                            \"B\", \"CH\", \"D\", \"DH\",\n",
    "                            \"EH0\", \"EH1\", \"ER0\", \"ER1\", \"EY0\", \"EY1\",\n",
    "                            \"F\", \"G\", \"HH\",\n",
    "                            \"IH0\", \"IH1\", \"IY0\", \"IY1\",\n",
    "                            \"JH\", \"K\", \"L\", \"M\", \"N\", \"NG\",\n",
    "                            \"OW0\", \"OW1\", \"OY0\", \"OY1\",\n",
    "                            \"P\", \"R\", \"S\", \"SH\", \"T\", \"TH\",\n",
    "                            \"UH0\", \"UH1\", \"UW0\", \"UW1\",\n",
    "                            \"V\", \"W\", \"Y\", \"Z\", \"ZH\"]\n",
    "\n",
    "        self.dictionary = {c: i for i, c in enumerate(self.rdictionary)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rdictionary)\n",
    "\n",
    "    def encode(self, text):\n",
    "        labels = [c.replace('2', '0') for c in self.g2p(text) if c != \"'\"]\n",
    "        targets = torch.LongTensor([self.dictionary[phoneme] for phoneme in labels])\n",
    "        return targets\n",
    "\n",
    "    \n",
    "class Recognizer(nn.Module):\n",
    "    def __init__(self, feat_dim=1024, vocab_size=55+1):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Linear(feat_dim, vocab_size)\n",
    "\n",
    "    def forward(self, features):\n",
    "        features = self.classifier(features)\n",
    "        return features.log_softmax(dim=-1)"
   ],
   "metadata": {
    "id": "cBfJ5X_C-goN"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "vocab = Vocabulary()\n",
    "encoder = Encoder()\n",
    "recognizer = Recognizer()"
   ],
   "metadata": {
    "id": "FiVvD1x4-gqy"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ckpt = torch.load('/content/drive/MyDrive/Colab Notebooks/UCU_розпізнавання_мови/lstm_p3_360+500.pt', map_location='cpu')\n",
    "encoder.load_state_dict(ckpt['encoder'])\n",
    "recognizer.load_state_dict(ckpt['recognizer'])"
   ],
   "metadata": {
    "id": "Sqa4sik0-gtH",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "81b9ab7f-bb78-4220-d1ad-16c7a8452216"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "audio_frames, sr, text, speaker_id, chapter_id, utterance_id = LibriSpeech()[100]\n",
    "phonemes = vocab.encode(text)\n",
    "features = encoder(audio_frames)\n",
    "\n",
    "\n",
    "speaker_id, chapter_id, utterance_id"
   ],
   "metadata": {
    "id": "OPqr_gd1-gvh",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8f6176c6-1e17-43e4-c0a3-8cb46d95cf82"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 322M/322M [00:12<00:00, 28.0MB/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1462, 170138, 27)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "outputs = recognizer.forward(features) # (T, 55+1)"
   ],
   "metadata": {
    "id": "LLzDkph7_sC2"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "predicted_speech = torch.argmax(outputs, dim=1)\n",
    "predicted_speech_str = [vocab.rdictionary[idx] for idx in predicted_speech]\n",
    "print(predicted_speech_str)\n",
    "\n",
    "true_labels = [vocab.rdictionary[idx] for idx in phonemes]\n",
    "print(true_labels)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MXPow-DVjIry",
    "outputId": "37588f89-3b71-4ab0-f2fc-fef85042b23d"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['ε', 'ε', 'ε', 'ε', 'ε', 'ε', 'ε', 'ε', 'ε', 'ε', 'ε', 'ε', 'ε', 'IH1', 'IH1', 'T', ' ', ' ', 'W', 'AA1', 'Z', ' ', ' ', 'Y', 'Y', 'UW1', 'ε', 'ε', 'TH', ' ', ' ', ' ', 'AH0', 'N', 'D', ' ', ' ', 'P', 'ε', 'AA1', 'V', 'V', 'ER0', 'ER0', 'T', 'ε', 'IY0', ' ', ' ', 'ε', 'IH0', 'N', 'ε', ' ', ' ', 'P', 'R', 'AA0', 'K', 'ε', 'S', 'ε', 'IH1', 'M', 'ε', 'AH0', 'T', 'ε', 'IY0', 'ε', 'ε', 'ε', 'ε', 'ε', 'ε', 'ε', 'ε', ' ', ' ', ' ', 'AE1', 'T', ' ', ' ', 'EH1', 'V', 'R', 'IY0', 'IY0', 'TH', 'IH0', 'NG', ' ', ' ', 'W', 'AA1', 'Z', ' ', ' ', 'Y', 'ε', 'AH1', 'NG', 'ε', ' ', ' ', 'AH0', 'N', 'D', ' ', ' ', 'K', 'ε', 'AY1', 'N', 'D', 'D', 'L', 'IY0', 'IY0', 'ε', 'ε', 'ε', 'ε', 'ε', 'ε']\n",
      "['IH1', 'T', ' ', 'W', 'AA1', 'Z', ' ', 'Y', 'UW1', 'TH', ' ', 'AH0', 'N', 'D', ' ', 'P', 'AA1', 'V', 'ER0', 'T', 'IY0', ' ', 'AH0', 'N', 'D', ' ', 'P', 'R', 'AA0', 'K', 'S', 'IH1', 'M', 'AH0', 'T', 'IY0', ' ', 'AH0', 'N', 'D', ' ', 'EH1', 'V', 'R', 'IY0', 'TH', 'IH0', 'NG', ' ', 'W', 'AA1', 'Z', ' ', 'Y', 'AH1', 'NG', ' ', 'AH0', 'N', 'D', ' ', 'K', 'AY1', 'N', 'D', 'L', 'IY0']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "phonems_entries = []\n",
    "for idx, pred_token in enumerate(predicted_speech_str):\n",
    "  phonems_entries.append([((idx)*4/100), ((idx+1)*4/100), pred_token])\n",
    "\n",
    "\n",
    "# if we have similar phonemes in a row combine them into one and add the duration\n",
    "\n",
    "phonems_entries_concat = []\n",
    "\n",
    "last_entry = phonems_entries[0][2]\n",
    "start = phonems_entries[0][0]\n",
    "end = phonems_entries[0][1]\n",
    "\n",
    "for i in range(1, len(phonems_entries)):\n",
    "  if phonems_entries[i][2] == last_entry:\n",
    "    end = phonems_entries[i][1]\n",
    "  else:\n",
    "    phonems_entries_concat.append([start, end, last_entry])\n",
    "    last_entry = phonems_entries[i][2]\n",
    "    start = phonems_entries[i][0]\n",
    "    end = phonems_entries[i][1]\n"
   ],
   "metadata": {
    "id": "D-IAiJ3EmErW"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# generate a praat TextGrid\n",
    "intervals = defaultdict(list)\n",
    "tg = tgio.Textgrid()\n",
    "\n",
    "for idx, phonem_info in enumerate(phonems_entries_concat):\n",
    "    start = phonem_info[0]\n",
    "    end = phonem_info[1]\n",
    "    interval = Interval(start, end, phonem_info[2])\n",
    "    intervals[0].append(interval)\n",
    "\n",
    "\n",
    "tg = tgio.Textgrid()\n",
    "tg.minTimestamp = 0\n",
    "tg.maxTimestamp = intervals[0][-1].end\n",
    "\n",
    "tier_name = 'phones'\n",
    "tg.addTier(tgio.IntervalTier(tier_name, [], minT=0, maxT=tg.maxTimestamp))\n",
    "\n",
    "for interval in intervals[0]:\n",
    "    tg.getTier(tier_name).insertEntry(interval)\n",
    "\n",
    "tg.save('test_praat.TextGrid',\n",
    "        includeBlankSpaces=True,\n",
    "        format='long_textgrid',\n",
    "        reportingMode='error')"
   ],
   "metadata": {
    "id": "0tMpNTMQjwy-"
   },
   "execution_count": 10,
   "outputs": []
  }
 ]
}
